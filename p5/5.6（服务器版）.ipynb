{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dd52ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "第六关：机器学习算法实践实战Baseline（不使用GridSearchCV优化得分为0.74）\n",
    "\n",
    "大家可以通过学习基础代码，修改下面数据处理部分、模型调参等部分的代码，提高准确率\n",
    "具体修改的地方可以查看🚩标识处建议，可以使用Ctrl+f（Mac用户：command+f）查找\n",
    "\n",
    "在前面几关的学习中，总共学习了逻辑回归、KMeans、决策树、SVM 支持向量机和 XGBoost，我相信通过前面实际数据的模型实践和闯关题的解答，大家都已经学会了如何训练模型，那么我们就开始这个训练营的最后一关 堪培拉天气数据预测实战。\n",
    "\n",
    "下面我会给大家列出具体的实施步骤，需要大家补充完代码然后提交文件！大家可以参考之前的关卡完成实战项目。\n",
    "\n",
    "开始之前我先介绍下实战的数据集：\n",
    "\n",
    "train_weather.csv 训练数据集。\n",
    "test_weather.csv 提交测试数据集。\n",
    "submit_result.csv 提交结果数据集。\n",
    "数据集中的特征含义表示如下：\n",
    "\n",
    "特征列名称\t特征含义\n",
    "Date\t日期\n",
    "Location\t观察的城市\n",
    "MinTemp\t当天最低温度（摄氏度）\n",
    "MaxTemp\t当天最高温度（摄氏度）温度都是 string\n",
    "Rainfall\t当天的降雨量（单位是毫米mm）\n",
    "Evaporation\t一个凹地上面水的蒸发量（单位是毫米mm），24小时内到早上9点\n",
    "Sunshine\t一天中出太阳的小时数\n",
    "WindGustDir\t最强劲的那股风的风向，24小时内到午夜\n",
    "WindGustSpeed\t最强劲的那股风的风速（km/h），24小时内到午夜\n",
    "WindDir9am\t上午9点的风向\n",
    "WindDir3pm\t下午3点的风向\n",
    "WindSpeed9am\t上午9点之前的十分钟里的平均风速，即 8:50~9:00的平均风速，单位是（km/hr）\n",
    "WindSpeed3pm\t下午3点之前的十分钟里的平均风速，即 14:50~15:00的平均风速，单位是（km/hr）\n",
    "Humidity9am\t上午9点的湿度\n",
    "Humidity3pm\t下午3点的湿度\n",
    "Pressure9am\t上午9点的大气压强（hpa）\n",
    "Pressure3pm\t下午3点的大气压强\n",
    "Cloud9am\t上午9点天空中云的密度，取值是[0, 8]，以1位一个单位，0的话表示天空中几乎没云，8的话表示天空中几乎被云覆盖了\n",
    "Cloud3pm\t下午3点天空中云的密度\n",
    "Temp9am\t上午9点的温度（单位是摄氏度）\n",
    "Temp3pm\t下午3点的温度（单位是摄氏度）\n",
    "RainTomorrow\t明天是否下雨标签\n",
    "引入依赖\n",
    "如果你使用的机器学习方法为下面备注里的，则不用修改，否则请添加对应的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87406f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 引入依赖\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression # 逻辑回归\n",
    "from sklearn.tree import DecisionTreeClassifier     # 决策树\n",
    "from sklearn.ensemble import RandomForestClassifier # 随机森林\n",
    "from sklearn.svm import SVC                         # 支持向量机\n",
    "from sklearn.cluster import KMeans                  # Kmeans \n",
    "from xgboost import XGBClassifier                   # XGBoost\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccb9ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "加载数据（不用修改）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff58c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "\n",
    "train = pd.read_csv('/home/mw/input/canberraWeather2321/train_weather.csv', index_col='Unnamed: 0')\n",
    "test = pd.read_csv('/home/mw/input/canberraWeather2321/test_weather.csv', index_col='Unnamed: 0')\n",
    "submit = pd.read_csv('/home/mw/input/canberraWeather2321/submit_result.csv', index_col='Unnamed: 0')\n",
    "\n",
    "\n",
    "# 查看数据集，了解数据集格式\n",
    "print(\"训练集：\\n\")\n",
    "print(train.head())\n",
    "print(\"测试集：\\n\")\n",
    "print(test.head())\n",
    "print(\"提交集：\\n\")\n",
    "print(submit.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4b1c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "数据基础性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb920c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看训练集和结果集数据空值、类型\n",
    "print(\"========训练集=======\\n\")\n",
    "print(train.info())\n",
    "print(\"========测试集=======\\n\")\n",
    "print(test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ded18be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练集和结果集基础分析查看（是否有非法数据）\n",
    "# 🔔提示❗️❗️🔔：训练集与测试集都有非法数据，注意表格里数据的范围与题目要求的数据范围\n",
    "\n",
    "print(\"=== 训练集数值特征统计 ===\")\n",
    "display(train.describe().T)\n",
    "\n",
    "print(\"=== 测试集数值特征统计 ===\")\n",
    "display(test.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369a70b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "异常数据处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9addce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 非法值处理，训练集和测试集中均存在非法值，删除对应数据的索引 index（测试集中若出现非法值，提交答案集中的响应index 也需要删除）\n",
    "# 提示🔔：\n",
    "# 步骤一1️⃣：找到非法值的索引\n",
    "test[test['Cloud9am'] == 9].index, train[train['Cloud3pm'] == 9].index\n",
    "# 返回的内容为非法值的索引:前为训练集，后为测试集\n",
    "# (Int64Index([索引], dtype='int64'), Int64Index([索引], dtype='int64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332bbc1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步骤二2️⃣：删除对应的索引\n",
    "\n",
    "train = train.drop([88723])\n",
    "# submit 与 test 删除相同的索引是因为 test 最终的预测结果会缺失，而submit 也需要一致删除，这俩索引一样\n",
    "test = test.drop([20890, 22448])\n",
    "submit = submit.drop([20890, 22448]) # submit 与 test 删除相同的索引是因为 test 最终的预测结果会缺失，而submit 也需要一致删除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6d6422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 更改索引为日期\n",
    "# 训练集\n",
    "train.set_index('Date', inplace=True)\n",
    "# 测试集\n",
    "test.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9bee38",
   "metadata": {},
   "outputs": [],
   "source": [
    "数据处理，下面的代码可以开始修改了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0316d496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 离散型数据处理缺失值\n",
    "# 离散型数据则是指只能取到有限个数或者是可数个数的数据，通常以整数表示。\n",
    "# 🚩：我这里用的是众数，你也可以中位数、平均数等等，想想哪个更好\n",
    "# 这里需要单独对训练集和测试集分别处理，因为测试集中没有 RainTomorrow 字段\n",
    "\n",
    "cate_columns = ['RainTomorrow', 'WindDir3pm', 'WindDir9am', 'WindGustDir']\n",
    "\n",
    "si = SimpleImputer(missing_values=np.nan,strategy=\"most_frequent\") # 使用众数填充缺失值\n",
    " \n",
    "# 步骤1：用训练集拟合规则    \n",
    "si.fit(train.loc[:, cate_columns])   \n",
    "# 步骤2：填充训练集缺失值    \n",
    "train.loc[:, cate_columns] = si.transform(train.loc[:, cate_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a35a437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集\n",
    "cate_columns = ['WindDir3pm', 'WindDir9am', 'WindGustDir']\n",
    "# 🚩：我这里用的是众数，你也可以中位数、平均数等等，想想哪个更好\n",
    "si = SimpleImputer(missing_values=np.nan,strategy=\"most_frequent\") # 使用众数填充缺失值\n",
    "\n",
    "# 这里需要单独对训练集和测试集分别处理，因为测试集中没有 RainTomorrow 字段\n",
    "# 步骤1   \n",
    "si.fit(test.loc[:, cate_columns])\n",
    "# 步骤2  \n",
    "test.loc[:, cate_columns] = si.transform(test.loc[:, cate_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354320c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 连续型数据处理缺失值\n",
    "# 连续型数据是指可以取到某个区间内的任意值的数据，通常以实数表示。\n",
    "# 🚩：我这里用的是平均数，你也可以用众数、中位数、等等，想想哪个更好\n",
    "cate_columns = ['RainTomorrow', 'WindDir3pm', 'WindDir9am', 'WindGustDir', 'Location']\n",
    "\n",
    "columns = train.columns.to_list()\n",
    "for col in cate_columns:\n",
    "    columns.remove(col)\n",
    "\n",
    "impmean = SimpleImputer(missing_values=np.nan,strategy = \"median\")\n",
    "# 步骤1 \n",
    "impmean = impmean.fit(train.loc[:, columns])\n",
    "# 步骤2\n",
    "train.loc[:, columns] = impmean.transform(train.loc[:, columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daf87460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集\n",
    "\n",
    "cate_columns = ['WindDir3pm', 'WindDir9am', 'WindGustDir', 'Location']\n",
    "\n",
    "columns = test.columns.to_list()\n",
    "for col in cate_columns:\n",
    "    columns.remove(col)\n",
    "# 🚩：我这里用的是平均数，你也可以用众数、中位数、等等，想想哪个更好\n",
    "impmean = SimpleImputer(missing_values=np.nan,strategy = \"median\")\n",
    "# 步骤1 \n",
    "impmean = impmean.fit(test.loc[:, columns])\n",
    "# 步骤2\n",
    "test.loc[:, columns] = impmean.transform(test.loc[:, columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e795d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正确处理的标志：下面的输出全是'0'\n",
    "train.isnull().sum(), test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcdb3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 离散型数据标准化\n",
    "\n",
    "cate_columns = ['RainTomorrow', 'WindDir3pm', 'WindDir9am', 'WindGustDir', 'Location']\n",
    "lb = LabelEncoder()\n",
    "\n",
    "# 用LabelEncoder将离散特征（如风向、是否下雨）转为数值型，便于模型处理：\n",
    "for col in cate_columns:\n",
    "    # 下面三行代码都是打印信息，方便读者查看\n",
    "    print('-'*50)\n",
    "    print(train[col].unique())\n",
    "    print(train[col].value_counts())\n",
    "    \n",
    "    # 步骤1：用训练集拟合编码器规则\n",
    "    lb.fit(train[col])\n",
    "    \n",
    "    # 步骤2：使用拟合好的规则转换训练集\n",
    "    train[col] = lb.transform(train[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41db9d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试集\n",
    "\n",
    "cate_columns = ['WindDir3pm', 'WindDir9am', 'WindGustDir', 'Location']\n",
    "lb = LabelEncoder()\n",
    "\n",
    "for col in cate_columns:\n",
    "    # 下面三行代码都是打印信息，方便读者查看\n",
    "    print('-'*50)\n",
    "    print(train[col].unique())\n",
    "    print(train[col].value_counts())\n",
    "    # 步骤1 \n",
    "    lb.fit(test[col])\n",
    "    \n",
    "    # 步骤2\n",
    "    test[col] = lb.transform(test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718f442c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征相关性\n",
    "\n",
    "sns.heatmap(train.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7966643",
   "metadata": {},
   "outputs": [],
   "source": [
    "训练模型\n",
    "你可以使用 逻辑回归、支持向量机、决策树、XGBoost等多种我们学习过的机器学习方法\n",
    "下面的代码采用随机森林，仅为参考，无法通关本训练营\n",
    "请你参考下面的代码，自行修改，找到最佳模型与参数\n",
    "\n",
    "推荐使用 XGBoost\n",
    "其他算法经测试合理的参数也是可以通关的\n",
    "训练时间大约在2～8小时，具体时间根据选择的算法不同有所不同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa6d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切分训练集和测试集\n",
    "\n",
    "x = train.drop('RainTomorrow', axis=1)\n",
    "y = train['RainTomorrow']\n",
    "\n",
    "# 🚩：你可以自由划分test_size的大小，我这里是0.5，显然不合理，随机数种子也可以自由修改\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "# 查看信息\n",
    "x_train.head(), x_test.head(), y_train.head(), y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a53032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🚩：构建模型，修改下面的代码，但是不要修改变量名：'model'\n",
    "\n",
    "'''\n",
    "model = 模型名称(\n",
    "    # 模型参数\n",
    "    # 请你删除注释后在这里修改🚩\n",
    ")\n",
    "'''\n",
    "\n",
    "\n",
    "# 下面代码以随机森林为例\n",
    "'''\n",
    "随机森林基于决策树，其主要参数有：\n",
    "1. 控制树数量的参数：\n",
    "   n_estimators: 森林中决策树的数量\n",
    "\n",
    "2. 控制单棵树结构的参数（与决策树共享）：\n",
    "   max_depth: 每棵树的最大深度。\n",
    "   min_samples_split: 节点分裂所需的最小样本数。\n",
    "   min_samples_leaf: 叶节点所需的最小样本数。\n",
    "   max_features: 分裂时考虑的最大特征数。（默认'sqrt'，即√n）。\n",
    "\n",
    "3. 计算优化参数：\n",
    "   n_jobs: 并行训练的CPU核心数（默认1）。设置为-1表示使用所有可用核心。\n",
    "   random_state: 随机种子，保证结果可复现（默认None）。\n",
    "'''\n",
    "\n",
    "# 🚩：构建模型，修改下面的代码，但是不要修改变量名：'model'\n",
    "\n",
    "# --------------------- 修改部分 ---------------------\n",
    "# 使用 XGBoost 分类器代替随机森林，XGBoost 在此类竞赛中通常性能更佳。\n",
    "# 参数说明:\n",
    "# n_estimators: 树的数量，即迭代次数。\n",
    "# max_depth: 每棵树的最大深度，用于防止过拟合。\n",
    "# learning_rate: 学习率，控制每次迭代的步长。\n",
    "# use_label_encoder=False: 避免新版本 XGBoost 的警告，因为我们已经手动完成了编码。\n",
    "# eval_metric='logloss': 指定评估指标为对数损失，适用于二分类问题。\n",
    "model = XGBClassifier(\n",
    "    n_estimators=200,          # 树的数量\n",
    "    max_depth=5,               # 树的最大深度\n",
    "    learning_rate=0.1,         # 学习率\n",
    "    use_label_encoder=False,   # 关闭自动标签编码\n",
    "    eval_metric='logloss',     # 评估指标\n",
    "    n_jobs=-1,                 # 使用所有CPU核心进行并行计算\n",
    "    random_state=42            # 随机种子，保证结果可复现\n",
    ")\n",
    "# ----------------------------------------------------\n",
    "\n",
    "# 训练模型（不要修改代码）\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed49e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测测试集并计算指标（不要修改代码）\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7f03d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算准确率（不要修改代码）\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc9a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型调参（具体参数需要根据你的模型来修改，可以回顾前面学过的内容～）\n",
    "# 🚩：请修改{}内的代码\n",
    "# --------------------- 修改部分 ---------------------\n",
    "# 为 XGBoost 模型创建一个参数网格，用于 GridSearchCV 寻找最优参数。\n",
    "# n_estimators: 尝试不同的树的数量。\n",
    "# max_depth: 尝试不同的树深度，控制模型复杂度。\n",
    "# learning_rate: 尝试不同的学习率。\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [3, 5],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "}\n",
    "# ----------------------------------------------------\n",
    "# GridSearchCV\n",
    "# 不要动下面的代码\n",
    "# 注意：这里的 estimator 需要是我们新定义的 XGBoost 模型，而不是随机森林。\n",
    "# 我们需要重新创建一个基础模型实例传给 GridSearchCV。\n",
    "xgb_for_grid = XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_jobs=-1, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_for_grid, param_grid=param_grid, cv=3, scoring='accuracy', verbose=2) # cv=3 为了加快演示速度\n",
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e94c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最佳参数和最高准确率\n",
    "grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4141970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算结果集并保存\n",
    "result = model.predict(test)\n",
    "\n",
    "# 保存预测结果并保存为文件，这里要注意因为测试集存在非法值，有一部分数据被删除，所以submit 中对应索引的行也要被删除\n",
    "submit['RainTomorrow'] = result\n",
    "\n",
    "submit.to_csv(\"submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5a308c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#运行这个Cell 下载提交工具\n",
    "\n",
    "!wget -nv -O heywhale_submit https://cdn.kesci.com/submit_tool/v4/heywhale_submit&&chmod +x heywhale_submit\n",
    "\n",
    "# 运行提交工具\n",
    "# 把下方XXXXXXX替换为你的 Token\n",
    "\n",
    "!./heywhale_submit -token XXXXXXX -file submit.csv  # 替换XXXXXXX；注意不可增减任何空格或其他"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
